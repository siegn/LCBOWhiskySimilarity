{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-Libraries-and-Data\" data-toc-modified-id=\"Load-Libraries-and-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load Libraries and Data</a></span></li><li><span><a href=\"#Initial-Grouping\" data-toc-modified-id=\"Initial-Grouping-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Initial Grouping</a></span></li><li><span><a href=\"#Extract-Keywords\" data-toc-modified-id=\"Extract-Keywords-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Extract Keywords</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find-Keywords-from-Distillery-Names-(And-Other-Important-Terms)\" data-toc-modified-id=\"Find-Keywords-from-Distillery-Names-(And-Other-Important-Terms)-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Find Keywords from Distillery Names (And Other Important Terms)</a></span></li><li><span><a href=\"#Extract-Keywords\" data-toc-modified-id=\"Extract-Keywords-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Extract Keywords</a></span></li></ul></li><li><span><a href=\"#Extract-Age\" data-toc-modified-id=\"Extract-Age-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Extract Age</a></span></li><li><span><a href=\"#Join-Datasets\" data-toc-modified-id=\"Join-Datasets-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Join Datasets</a></span><ul class=\"toc-item\"><li><span><a href=\"#Join\" data-toc-modified-id=\"Join-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Join</a></span></li><li><span><a href=\"#Fuzzy-Match\" data-toc-modified-id=\"Fuzzy-Match-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Fuzzy Match</a></span></li><li><span><a href=\"#Add-Age\" data-toc-modified-id=\"Add-Age-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Add Age</a></span></li><li><span><a href=\"#Filter-NonMatching\" data-toc-modified-id=\"Filter-NonMatching-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Filter NonMatching</a></span></li></ul></li><li><span><a href=\"#Save-to-File\" data-toc-modified-id=\"Save-to-File-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Save to File</a></span><ul class=\"toc-item\"><li><span><a href=\"#Additional-Investigation\" data-toc-modified-id=\"Additional-Investigation-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Additional Investigation</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Purpose\n",
    "This notebook is to combine the reddit reviews with the LCBO product data.\n",
    "The difficulty in doing this comes from differing whisky names.\n",
    "To accomplish the join first we create a list of key phrases and extract them from the names. If whiskies have different key phrases, they do not match. Then we pull out the age of the whisky and compare that as well. Lastly, in terms of cases where there are still duplicates we use a fuzzy matching algorithm and take the highest rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:04:34.981965Z",
     "start_time": "2019-07-29T18:04:34.975522Z"
    }
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import sys\n",
    "import pdb\n",
    "from fuzzywuzzy import fuzz\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:04:37.622497Z",
     "start_time": "2019-07-29T18:04:37.005703Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_parquet('data/db_reviews_split.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:04:39.576099Z",
     "start_time": "2019-07-29T18:04:39.480314Z"
    }
   },
   "outputs": [],
   "source": [
    "lcbo = pd.read_parquet('data/lcbo_whisky.parquet').drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Grouping\n",
    "LCBO has some duplicate products due to having different bottle sizes or materials. We don't care about this so will group items by whisky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:04:42.342600Z",
     "start_time": "2019-07-29T18:04:42.126017Z"
    }
   },
   "outputs": [],
   "source": [
    "# we actually don't care if a product is in a plastic bottle or not for review purposes, so let's rename them:\n",
    "lcbo['itemname'] = lcbo['itemname'].str.replace('\\(PET\\)','', case=False,regex=True).str.strip()\n",
    "\n",
    "# add count to see how many of the same whisky name we have\n",
    "lcbo['count'] = lcbo.groupby('itemname')['itemnumber'].transform('count')\n",
    "\n",
    "# add a metric to see how far from 750 a bottle is (we want to drop duplicate products of different sizes)\n",
    "lcbo = lcbo.assign(sizedelta = abs(lcbo['productsize'] - 750))\n",
    "\n",
    "# keep only the entry closest to 750 and in case of tie the one with higher price (assuming its the nonpet) :\n",
    "lcbo['rank'] = lcbo.groupby(\"itemname\")['sizedelta'].rank(\"first\", ascending=True)\n",
    "lcbo = lcbo[(lcbo['rank'] == 1)]\n",
    "\n",
    "# drop the added columns since we don't need them anymore\n",
    "lcbo = lcbo.drop(['count','sizedelta','rank'], axis='columns')\n",
    "\n",
    "# while we are here we need to fix the name of a specific whisky:\n",
    "lcbo.loc[lcbo.itemname.str.contains('GLENFARCLAS12'),'itemname'] = \"GLENFARCLAS 12-YEAR-OLD HIGHLAND SINGLE MALT SCOTCH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the naming prevents our keyword matchups so we have to upfront change a couple of whisky names in the reviews table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:04:53.297176Z",
     "start_time": "2019-07-29T18:04:53.191763Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews.loc[reviews.whisky.str.contains('Jim Beam Legent'),'whisky'] = \"Legent\"\n",
    "reviews.loc[reviews.whisky.str.contains('Bruichladdich Black Art 6.1'),'whisky'] = \"Black Art 6.1\"\n",
    "reviews.loc[reviews.whisky.str.contains('Last Straw Darker Side of the Moonshine'),'whisky'] = \"Darker Side\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Keywords from Distillery Names (And Other Important Terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:04:55.463023Z",
     "start_time": "2019-07-29T18:04:55.455549Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_nonwords(sentence):\n",
    "    #return nltk.word_tokenize(sentence)\n",
    "    return [str.lower(word) for word in nltk.word_tokenize(sentence) if not is_word(word)]\n",
    "    \n",
    "def is_word(word):\n",
    "    if wordnet.synsets(word):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def contains_digit(word):\n",
    "    return any(char.isdigit() for char in word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:04:59.237709Z",
     "start_time": "2019-07-29T18:04:58.622620Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find all words in whisky names that are not english words\n",
    "keywords = lcbo.apply(lambda row: find_nonwords(row['itemname']), axis='columns')\n",
    "\n",
    "# Turn into one list without duplicates\n",
    "keywords = list(keywords.apply(pd.Series).stack().unique())\n",
    "\n",
    "# Filter out purly numeric values\n",
    "keywords = [word for word in keywords if not contains_digit(word)]\n",
    "\n",
    "# Filter out stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "keywords = [word for word in keywords if word not in stopWords]\n",
    "\n",
    "# Filter out punctuation\n",
    "keywords = [word for word in keywords if re.match('^[\\w]+$', word) is not None]\n",
    "\n",
    "# Filter out words that aren't applicable:\n",
    "# These are either: generic descriptors or whisky regions\n",
    "filterlist = ['peated', 'campbeltown', 'speyside', 'yo', 'st', 'oaked', 'wheated', 'ol', 'bbq', 'exper']\n",
    "\n",
    "keywords = [word for word in keywords if word not in filterlist]\n",
    "\n",
    "newwords = [\n",
    "            # brands\n",
    "            '101','1792', '6.1', 'gibsons', 'signature', 'ballantines',\n",
    "            'makers', 'bakers','blantons','mcclelland','bookers','patricks','gentleman','jack',\n",
    "            'prichards','stranahans','dewars',\n",
    "            'jeffersons','liquormens', \n",
    "            'barrelling','cattos','blantons','founders',\n",
    "            'walkers','teachers','bells','royal','grants','o.f.c.', 'century',\n",
    "            # bigrams need to both be matched:\n",
    "            ('jack','daniels'), ('knob','creek'),('crown','royal'),('canadian','club'),\n",
    "            ('highland','park'), ('forty','creek'),('proof', 'whisky'), ('canadian','rockies'),\n",
    "            'owl', 'jefferson', 'teacher',\n",
    "            'sazerac', 'caribou', 'wiser', 'walker', 'grouse', 'alberta', 'grant', 'bell', \n",
    "            'dewar',  'rittenhouse', 'revel', 'roses', \n",
    "            'writers', 'writer', 'rogue',  'colonel', 'weller', 'booker', 'mist', 'challenge',\n",
    "            'redbreast','jts', 'casg','burns', '601',\n",
    "            # qualities\n",
    "            'organic','vintage','quiet', 'classic', 'select', #'proof', 'rare', \n",
    "            # region (careful with these)\n",
    "             'canada', #'islay', 'canadian',\n",
    "            # locations\n",
    "            'virginia','dublin','shetland','trafalgar','caribbean','windsor',  'halifax',\n",
    "            # names\n",
    "            'patrick', 'gretzky', 'cody', 'charlotte','tucker','prescott',\n",
    "            # animals\n",
    "            'bull', 'dog', 'turkey', 'monkey', 'beast', 'fox', 'buffalo','crow','horse', \n",
    "            # colors\n",
    "            'red', 'blue', 'yellow', 'green', 'black', 'brown', 'white', 'gold', 'silver', #'copper',\n",
    "            'golden','blacker', 'golder', 'redder', 'darker',\n",
    "            'dark',\n",
    "            # type\n",
    "            'rye',\n",
    "            # barrels\n",
    "            'cognac', 'sherry', 'amarone', 'champagne', #'stout', messes up caskmates\n",
    "            'brandy', 'madeira', 'bordeaux', 'sauternes', 'burgundy',\n",
    "            'sassicaia', 'tokaji', 'rum', 'sherry'\n",
    "            # barrel count\n",
    "            'triple', 'double', #'single',\n",
    "            # woods\n",
    "            'cedar', 'heartwood', 'springwood', 'virgin', 'redwood', 'wood', 'cork', 'cask', 'new',\n",
    "            # game of thrones\n",
    "            'stark', 'tully',\n",
    "            # flavours\n",
    "            'apple', 'vanilla', 'peach', 'honey', 'maple', 'spiced', 'toasted', 'seasoned',\n",
    "            # other\n",
    "            #'small',\n",
    "            'irishman', 'rebel', 'compass',   \n",
    "            'stalk', 'centennial', 'forester', 'powers', 'temple', \n",
    "            'antiquity', 'feathery', 'few',  'burnside',   'larceny', 'tango', 'king',\n",
    "            'moray', 'twelve', 'reunion',   'maestri', #'reserve', \n",
    "            'sexton', 'ezra', 'bastille',  'orphan', 'founder',  'wedding', 'shoe',\n",
    "            'caramel', 'moonshine', 'cooper',  'benchmark',\n",
    "            'smws','valinch', 'hermitage','home',    'traditional', 'bush', 'art','diamond', \n",
    "            'alpha', 'dawn', 'dusk', 'surf', 'elements', 'growth', 'bere', \n",
    "            'cuvee', 'infinity', 'octomore', 'resurrection',\n",
    "            'waves', 'river', 'silk' ,'signal', 'winter', 'snow', 'ice', 'fire', \n",
    "            'harvest', 'blenders', 'chairman','ellington', 'kirkland',\n",
    "            'mcadam', 'glacier', 'skate', 'pike', 'ileach',\n",
    "            'macaloney', 'cured', 'grain',  'sour', 'tornado',\n",
    "            'hedonism', 'evolution', 'cross', 'glasgow','indian',\n",
    "            'heritage',  'devil', 'brooks', 'alba', 'major', 'naked', 'eades', 'light',  'entrapment',  'oyo',\n",
    "            'palm', 'lochnagar', 'willett', 'north', 'dissertation', 'last', 'legacy'\n",
    "           ]\n",
    "keywords = keywords + newwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:05:03.618964Z",
     "start_time": "2019-07-29T18:05:03.590750Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract keywords from text\n",
    "def extract_keywords(text, keywords):\n",
    "    from nltk import ngrams\n",
    "    text = text.lower().replace(\"mcclelland's\",\"mcclelland\")\n",
    "    text = text.lower().replace(\"hayden's\",\"hayden\")\n",
    "    text = text.lower().replace(\"'s\",\"s\")\n",
    "    result = []\n",
    "    for k in keywords:\n",
    "        if type(k) == tuple:\n",
    "            # lower each word in the tuple and turn into a string\n",
    "            (word1, word2) = k\n",
    "            k = \" \".join([word1.lower(),word2.lower()])\n",
    "        else:\n",
    "            # lower the word\n",
    "            k = k.lower()\n",
    "        count = len([gram for gram in ngrams(nltk.word_tokenize(text),len(nltk.word_tokenize(k))) if gram == tuple(nltk.word_tokenize(k))])\n",
    "        if count > 0:\n",
    "            result.append(k.replace(' ','_'))\n",
    "    return \" \".join(sorted(result))\n",
    "\n",
    "# Function to multiprocess an entire dataframe\n",
    "def extract_keywords_dataframe(df, columnname, keywords):\n",
    "    # create dataframe to hold results\n",
    "    global results\n",
    "    results = pd.DataFrame(columns=[columnname,'keywords'])\n",
    "    \n",
    "    # select only the column we want and make unique to save some time\n",
    "    dfnames = df[columnname].unique()\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    \n",
    "    # call function for each name\n",
    "    for name in dfnames:\n",
    "        pool.apply_async(extract_keywords_row, args=(columnname, name, keywords), callback=collect_result)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    # join back on original dataframe\n",
    "    return (df.set_index(columnname)\n",
    "              .join(results.set_index(columnname))\n",
    "              .reset_index()\n",
    "              .rename({'index':columnname}, axis='columns')\n",
    "           )\n",
    "    \n",
    "# Function to be ran in multiprocess on each item\n",
    "def extract_keywords_row(columnname, text, keywords):\n",
    "    newitem = {}\n",
    "    newitem[columnname] = text\n",
    "    newitem['keywords'] = extract_keywords(text, keywords)\n",
    "    return newitem\n",
    "    \n",
    "# Function to collect results from multiprocess\n",
    "def collect_result(result):\n",
    "    global results\n",
    "    results = results.append(result,ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add keywords to LCBO data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:05:10.446578Z",
     "start_time": "2019-07-29T18:05:10.437908Z"
    }
   },
   "outputs": [],
   "source": [
    "results = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:06:02.090682Z",
     "start_time": "2019-07-29T18:05:14.278308Z"
    }
   },
   "outputs": [],
   "source": [
    "lcbo = extract_keywords_dataframe(lcbo, 'itemname', keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to review data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:22:38.164207Z",
     "start_time": "2019-07-29T18:10:35.364006Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31056, 15)\n",
      "(26277, 15)\n"
     ]
    }
   ],
   "source": [
    "reviews = extract_keywords_dataframe(reviews, 'whisky', keywords)\n",
    "print(reviews.shape)\n",
    "reviews = reviews[reviews['keywords'] !='']\n",
    "print(reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:54:04.835578Z",
     "start_time": "2019-07-29T18:54:03.954620Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews.to_parquet('db_reviews_keywords.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-29T04:16:15.565Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_parquet('db_reviews_keywords.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:54:07.228245Z",
     "start_time": "2019-07-29T18:54:07.217839Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_age(sentence):\n",
    "    # remove # words and No digit to not confuse age\n",
    "    sentence = re.sub(\"\\#\\d*\",'', sentence)\n",
    "    sentence = re.sub(\"NO\\. \\d*\",'', sentence)\n",
    "    # grab full words that are 1 or 2 digits only or end in yo, year, y\n",
    "    # but only if the word batch is not present\n",
    "    reg = '^(\\d\\d?)(?:yo|year|y|-year-old)?$'\n",
    "    batches = [word for word in nltk.word_tokenize(sentence) if word in ['batch']]\n",
    "    if len(batches) == 0:\n",
    "        return \" \".join(sorted([re.findall(reg,word, re.IGNORECASE)[0] for word in nltk.word_tokenize(sentence) if re.match(reg, word, re.IGNORECASE) is not None]))\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T18:07:32.153434Z",
     "start_time": "2019-07-28T18:07:32.150287Z"
    }
   },
   "source": [
    "### Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a unique IDs to each whisky in the reviews table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:54:12.216022Z",
     "start_time": "2019-07-29T18:54:12.155920Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = reviews.assign(RedditWhiskyID = reviews['whisky'].astype('category').cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join on lcbo based on keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:54:14.879321Z",
     "start_time": "2019-07-29T18:54:14.074062Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = (reviews.set_index('keywords')\n",
    "                  .join(lcbo.set_index('keywords'), how='inner')\n",
    "                  .reset_index()\n",
    "                  .rename({'index':'keywords'}, axis='columns')\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:54:15.993629Z",
     "start_time": "2019-07-29T18:54:15.987396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40209, 61)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:54:27.899173Z",
     "start_time": "2019-07-29T18:54:21.670422Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate fuzzmatch using fuzztset which yields the best results\n",
    "reviews = reviews.rename({'whisky':'RedditWhiskyName','itemname':'Name'},axis='columns')\n",
    "reviews['fuzztset']    = reviews.apply(lambda row: fuzz.token_set_ratio(row['RedditWhiskyName'],row['Name']), axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:54:27.988203Z",
     "start_time": "2019-07-29T18:54:27.904140Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add Rank column based on max fuzz\n",
    "fuzzfilter = reviews\n",
    "fuzzfilter[\"rank\"] = fuzzfilter.groupby(\"RedditWhiskyName\")[\"fuzztset\"].rank(\"dense\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:55:07.643452Z",
     "start_time": "2019-07-29T18:54:27.991297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add Age columns\n",
    "fuzzfilter['RedditAge'] = fuzzfilter.apply(lambda row: extract_age(row['RedditWhiskyName']), axis='columns')\n",
    "fuzzfilter['LcboAge']   = fuzzfilter.apply(lambda row: extract_age(row['Name'])            , axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter NonMatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:55:07.787589Z",
     "start_time": "2019-07-29T18:55:07.647580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40209, 65)\n",
      "(15695, 65)\n"
     ]
    }
   ],
   "source": [
    "# Filter out values where age does not match\n",
    "print(fuzzfilter.shape)\n",
    "fuzzfilter = fuzzfilter[fuzzfilter['RedditAge'] == fuzzfilter['LcboAge']]\n",
    "print(fuzzfilter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:55:07.809289Z",
     "start_time": "2019-07-29T18:55:07.791483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10732, 65)\n"
     ]
    }
   ],
   "source": [
    "# Let's set threshold at 59 %. This is based on some trial and error.\n",
    "matches = fuzzfilter[(fuzzfilter['rank'] == 1) & (fuzzfilter['fuzztset'] >= 59)]\n",
    "print(matches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:55:07.884470Z",
     "start_time": "2019-07-29T18:55:07.812427Z"
    }
   },
   "outputs": [],
   "source": [
    "# save to csv to view results\n",
    "matches[['RedditWhiskyName','Name','fuzztset']].to_csv('fuzztest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many we've matched up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T19:00:46.257684Z",
     "start_time": "2019-07-29T19:00:46.246911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(matches.groupby('Name')['reviewID'].count()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-29T04:16:15.812Z"
    }
   },
   "outputs": [],
   "source": [
    "lcbo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T19:00:49.061790Z",
     "start_time": "2019-07-29T19:00:49.054781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.47294938917976"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*421/573"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "73 % matched is pretty good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T19:00:54.362812Z",
     "start_time": "2019-07-29T19:00:53.887714Z"
    }
   },
   "outputs": [],
   "source": [
    "matches.to_parquet('data/matches.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at ones that were not matched and figure out why:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-29T04:16:15.885Z"
    }
   },
   "outputs": [],
   "source": [
    "lcbomatches = pd.DataFrame(matches.groupby('Name')['reviewID'].count())\n",
    "lcbomatches['matched'] = True\n",
    "lcbomatches = lcbomatches .drop('reviewID', axis='columns')\n",
    "\n",
    "lcbomatches = lcbo.set_index('itemname').join(lcbomatches)\n",
    "lcbomatches[lcbomatches['matched'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-29T04:16:15.901Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = \"BENCHMARK OLD NO. 8 BRAND KENTUCKY STRAIGHT BOURBON\"\n",
    "redditname = \"Benchmark\"\n",
    "print(extract_keywords(name, keywords))\n",
    "print(extract_keywords(redditname, keywords))\n",
    "print(fuzz.token_set_ratio(name,redditname))\n",
    "print(extract_age(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-29T04:16:15.909Z"
    }
   },
   "outputs": [],
   "source": [
    "re.sub(\"\\#\\d*\",'', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-29T04:16:15.921Z"
    }
   },
   "outputs": [],
   "source": [
    "fuzz.token_set_ratio(name,redditname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-29T04:16:15.930Z"
    }
   },
   "outputs": [],
   "source": [
    "rawreviews = pd.read_parquet('data/db_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-29T04:16:15.938Z"
    }
   },
   "outputs": [],
   "source": [
    "rawreviews[rawreviews['whisky'].str.contains('Darker Side')]\n",
    "#rawreviews[rawreviews['whisky'].str.contains('Dalmore') & rawreviews['whisky'].str.contains('Wood')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-29T04:16:15.946Z"
    }
   },
   "outputs": [],
   "source": [
    "rename in reddit reviews:\n",
    "Jim Beam Legent\n",
    "Legent\n",
    "Bruichladdich Black Art 6.1\n",
    "Black Art 6.1\n",
    "Last Straw Darker Side of the Moonshine\n",
    "Darker Side\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "378px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
