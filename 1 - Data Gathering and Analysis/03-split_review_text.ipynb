{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-Libraries-and-Data\" data-toc-modified-id=\"Load-Libraries-and-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load Libraries and Data</a></span></li><li><span><a href=\"#Extract-Review-Text\" data-toc-modified-id=\"Extract-Review-Text-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Extract Review Text</a></span></li><li><span><a href=\"#Save-to-File\" data-toc-modified-id=\"Save-to-File-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Save to File</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Purpose\n",
    "This notebook splits up the review text into the categories we need: Nose, Taste, Finish.\n",
    "This works by splitting the text into lines and using some regular expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T01:52:09.263640Z",
     "start_time": "2019-07-29T01:52:08.793098Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T01:52:09.922522Z",
     "start_time": "2019-07-29T01:52:09.267458Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/pyarrow/pandas_compat.py:708: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels = getattr(columns, 'labels', None) or [\n",
      "/opt/tljh/user/lib/python3.6/site-packages/pyarrow/pandas_compat.py:735: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  return pd.MultiIndex(levels=new_levels, labels=labels, names=columns.names)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/pyarrow/pandas_compat.py:752: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    }
   ],
   "source": [
    "rdb = pd.read_parquet('data/db_reviews.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at a review:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T01:52:09.944164Z",
     "start_time": "2019-07-29T01:52:09.925459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My wife and I are on a trip to Thailand to meet her family.  I've seen plenty of whisky here, mostly JW, but this one stood out from the rest.  100 pipers is not something I've seen before and it seems to have quite the following here.  It is a blend at 40% alcohol by volume and 35cl was 220 baht or about $8 Canadian.  I got it more as a novelty as I suspect it is the Thai equivalent of chivas or glenfiddich 12.\\n\\nColour: caramel, I suspect it is artificially coloured.\\n\\nNose: (I had some tiger balm on my hands so this may be *way* off) alcohol, little bit of leather and some hints of sweetness.\\n\\nPalate: very bland, I taste almost nothing really, a bit of woody flavour, the promise of leather and sweetness from the nose is gone.\\n\\nFinish: short and devoid of anything but alcohol.\\n\\nThis reminds me of a JW red or the cheap rye my Dad drank when I was a kid.  I bought it primarily for the novelty so I don't think it was a waste.  it is just not something I'd seek out again.\\n\\n68/100\\n\\nPS: Yes it is a photo essay of me drinking the scotch.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdb.iloc[0]['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can look through this by splitting on new lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T02:50:38.819869Z",
     "start_time": "2019-07-29T02:50:38.792501Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_categories(text,name):\n",
    "    nose_re = '.*nose.{,4}[:-]|\\*nose\\*?|[\\*\\s]n[:-]'\n",
    "    taste_re = '.*taste.{,4}[:-]|\\*taste\\*?|\\*palate\\*|.*palate.{,6}[:-]|[\\*\\s]t[:-]|[\\*\\s]p[:-]'\n",
    "    finish_re = '.*finish.{,4}[:-]|\\*finish\\*?|[\\*\\s]f[:-]'\n",
    "\n",
    "    # Initialize Collections\n",
    "    review_categories = ['','','']\n",
    "    review_count = [0,0,0]\n",
    "    \n",
    "    review = re.split(\"\\n+\", text.lower())\n",
    "    \n",
    "    for i, line in enumerate(review):\n",
    "        # for each line split\n",
    "        nose = re.findall(nose_re, line)\n",
    "        taste = re.findall(taste_re, line)\n",
    "        finish = re.findall(finish_re, line)\n",
    "              \n",
    "        searchresults = [nose, taste, finish]\n",
    "        for idx, result in enumerate(searchresults):\n",
    "            if result:\n",
    "                review_count[idx] += 1\n",
    "                # if the category title is on a line before the review:\n",
    "                if len(line) < 15 and i<len(review)-1:\n",
    "                    review_categories[idx] += review[i+1]\n",
    "                else:\n",
    "                # otherwise it's on the same line\n",
    "                    review_categories[idx] += line\n",
    "\n",
    "    return {'nose': re.sub(\"(nose)|\\*|:|>\",'', review_categories[0]),\n",
    "            'taste': re.sub(\"(taste)|(palate)|\\*|:|>\",'', review_categories[1]),\n",
    "            'finish':re.sub(\"(finish)|\\*|:|>\",'', review_categories[2])}\n",
    "                \n",
    "\n",
    "# Function to multiprocess an entire dataframe\n",
    "def extract_categories_dataframe(df, columnname):\n",
    "    # create dataframe to hold results\n",
    "    global results\n",
    "    results = pd.DataFrame(columns=['reviewID','results'])\n",
    "    \n",
    "    # select only the column we want and make unique to save some time\n",
    "    reviewlist = df[['reviewID','whisky', columnname]].drop_duplicates()\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    \n",
    "    # call function for each name\n",
    "    for review in reviewlist.itertuples():\n",
    "        pool.apply_async(extract_categories_row, args=(review.reviewID, review.review, review.whisky), callback=collect_result)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    # break out dictionary from results\n",
    "    results = pd.concat([results.drop(['results'], axis=1), results['results'].apply(pd.Series)], axis=1)\n",
    "    \n",
    "    # join back on original dataframe\n",
    "    return (df.set_index('reviewID')\n",
    "              .join(results.set_index('reviewID'))\n",
    "              .reset_index()\n",
    "              .rename({'index':'reviewID'}, axis='columns')\n",
    "           )\n",
    "    \n",
    "# Function to be ran in multiprocess on each item\n",
    "def extract_categories_row(reviewID, text, name):\n",
    "    newitem = {}\n",
    "    newitem['reviewID'] = reviewID\n",
    "    newitem['results'] = extract_categories(text, name)\n",
    "    return newitem\n",
    "    \n",
    "# Function to collect results from multiprocess\n",
    "def collect_result(result):\n",
    "    global results\n",
    "    results = results.append(result,ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Review Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out reviews without any text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T02:55:27.905464Z",
     "start_time": "2019-07-29T02:50:58.520758Z"
    }
   },
   "outputs": [],
   "source": [
    "results = None\n",
    "rdb = pd.read_parquet('data/db_reviews.parquet').reset_index().rename({'index':'reviewID'}, axis='columns')\n",
    "rdb = rdb[rdb['review'] != '']\n",
    "rdb = extract_categories_dataframe(rdb, 'review')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T03:47:52.856556Z",
     "start_time": "2019-07-29T03:47:51.809325Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/pyarrow/pandas_compat.py:114: FutureWarning: A future version of pandas will default to `skipna=True`. To silence this warning, pass `skipna=True|False` explicitly.\n",
      "  result = infer_dtype(pandas_collection)\n"
     ]
    }
   ],
   "source": [
    "rdb.to_parquet('data/db_reviews_split.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
